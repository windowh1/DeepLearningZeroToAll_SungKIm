---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Ensemble

```python
import numpy as np
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train, x_test = x_train / 255.0, x_test / 255.0
x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])

# parameters
nb_classes = 10
training_epochs = 15
batch_size = 100
total_batch = int(len(x_train) / batch_size)

y_train_new = np.zeros((len(y_train), nb_classes))
for i in range(len(y_train)):
    y_train_new[i, y_train[i]] = 1

y_test_new = np.zeros((len(y_test), nb_classes))
for i in range(len(y_test)):
    y_test_new[i, y_test[i]] = 1


# python Class
class Model:

    def __init__(self, sess, name):
        self.sess = sess
        self.name = name
        self._build_net()
    
    def _build_net(self):
        with tf.variable_scope(self.name):
            self.X = tf.placeholder(tf.float32, [None, 784])
            X_img = tf.reshape(self.X, [-1, 28, 28, 1])
            self.Y = tf.placeholder(tf.float32, [None, 10])
            self.rate = tf.placeholder(tf.float32)

            conv1 = tf.layers.conv2d(inputs = X_img, filters = 32, kernel_size = [3, 3], padding = 'SAME', activation = tf.nn.relu)
            pool1 = tf.layers.max_pooling2d(inputs = conv1, pool_size = [2, 2], padding = 'SAME', strides = 2)
            dropout1 = tf.layers.dropout(inputs = pool1, rate = self.rate)

            conv2 = tf.layers.conv2d(inputs = dropout1, filters = 64, kernel_size = [3, 3], padding = 'SAME', activation = tf.nn.relu)
            pool2 = tf.layers.max_pooling2d(inputs = conv2, pool_size = [2, 2], padding = 'SAME', strides = 2)
            dropout2 = tf.layers.dropout(inputs = pool2, rate = self.rate)

            conv3 = tf.layers.conv2d(inputs = dropout2, filters = 128, kernel_size = [3, 3], padding = 'SAME', activation = tf.nn.relu)
            pool3 = tf.layers.max_pooling2d(inputs = conv3, pool_size = [2, 2], padding = 'SAME', strides = 2)
            dropout3 = tf.layers.dropout(inputs = pool3, rate = self.rate)
            flat = tf.reshape(dropout3, [-1, 4 * 4 * 128])

            dense4 = tf.layers.dense(inputs = flat, units = 625, activation = tf.nn.relu)
            dropout4 = tf.layers.dropout(inputs = dense4, rate = self.rate)

            self.dense5 = tf.layers.dense(inputs = dropout4, units = 10)

            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.dense5, labels = self.Y))
            self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(self.cost)
            self.correct_prediction = tf.equal(tf.argmax(self.dense5, 1), tf.argmax(self.Y, 1))
            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))

    def train(self, x_data, y_data):
        return self.sess.run([self.cost, self.optimizer], feed_dict = {self.X : x_data, self.Y : y_data, self.rate : 0.2})

    def predict(self, x_test):
        return self.sess.run(self.dense5, feed_dict = {self.X : x_test, self.rate : 0.0})
    
    def get_accuracy(self, x_test, y_test):
        return self.sess.run(self.accuracy, feed_dict = {self.X : x_test, self.Y : y_test, self.rate : 0.0})


sess = tf.Session()

models = []
num_models = 7

for m in range(num_models):
    models.append(Model(sess, "model" + str(m + 1)))

sess.run(tf.global_variables_initializer())

for epoch in range(training_epochs):
    avg_cost_list = np.zeros(len(models)) # model 7개 각각에서 나오는 cost를 기록할 list
    for i in range(total_batch):
        batch_xs = x_train[i * batch_size : (i+1) * batch_size]
        batch_ys = y_train_new[i * batch_size : (i+1) * batch_size]
        for m_idx, m in enumerate(models):
            c, _ = m.train(batch_xs, batch_ys)
            avg_cost_list[m_idx] += c / total_batch
        
    print("Epoch:", epoch, "Cost:", avg_cost_list)


predictions = np.zeros(len(x_test) * 10).reshape(len(x_test), 10)

for m_idx, m in enumerate(models):
    print(m_idx, 'Accuracy:', m.get_accuracy(x_test, y_test_new))
    p = m.predict(x_test)
    predictions += p

ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y_test_new, 1))
ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))
print('Ensemble Accuracy:', sess.run(ensemble_accuracy))
```
